{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled288.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8+tmaBeF4oKwFxF4reTE9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyasi345/textclassification_3classes/blob/master/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_yg-FY5MfwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "43147284-5fff-4912-8aab-d85919461c7a"
      },
      "source": [
        " import nltk\n",
        " nltk.download('stopwords')\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxiBuTziMZlw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81549db9-2f5a-4e79-fc30-5c22bbd5e0fa"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVVOPzE6Obb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a67ff19a-06ef-44af-8570-c14c55bbf896"
      },
      "source": [
        "!unzip sample_submission.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_submission.zip\n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oiIYW28PTrz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "db2d79c5-407f-4881-dd42-39d7bf265879"
      },
      "source": [
        "!unzip test.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DJTQxNUPbuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f05668a6-e903-4f54-d58c-2b2bade0d0c2"
      },
      "source": [
        "!unzip train.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebDVCWUAMazZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "sample = pd.read_csv('/content/sample_submission.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8LsnXC9MdbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "456554f0-59fa-4b9e-e9b4-97d6e51f1826"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCK7cn0wMkYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ffdec976-5895-4199-d2f6-cd9e4d5e31d4"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>And when they had broken down the frail door t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>While I was thinking how I should possibly man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>I am not sure to what limit his knowledge may ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text\n",
              "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
              "1  id24541  If a fire wanted fanning, it could readily be ...\n",
              "2  id00134  And when they had broken down the frail door t...\n",
              "3  id27757  While I was thinking how I should possibly man...\n",
              "4  id04081  I am not sure to what limit his knowledge may ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-H3WOJqMl-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a2711cd3-2711-47fd-ac02-8a23493799d3"
      },
      "source": [
        "sample.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>EAP</th>\n",
              "      <th>HPL</th>\n",
              "      <th>MWS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>0.403494</td>\n",
              "      <td>0.287808</td>\n",
              "      <td>0.308698</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id       EAP       HPL       MWS\n",
              "0  id02310  0.403494  0.287808  0.308698\n",
              "1  id24541  0.403494  0.287808  0.308698\n",
              "2  id00134  0.403494  0.287808  0.308698\n",
              "3  id27757  0.403494  0.287808  0.308698\n",
              "4  id04081  0.403494  0.287808  0.308698"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8swD6XkMMolk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
        "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
        "    :param actual: Array containing the actual target classes\n",
        "    :param predicted: Matrix with class predictions, one probability per class\n",
        "    \"\"\"\n",
        "    # Convert 'actual' to a binary array if it's not already:\n",
        "    if len(actual.shape) == 1:\n",
        "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
        "        for i, val in enumerate(actual):\n",
        "            actual2[i, val] = 1\n",
        "        actual = actual2\n",
        "\n",
        "    clip = np.clip(predicted, eps, 1 - eps)\n",
        "    rows = actual.shape[0]\n",
        "    vsota = np.sum(actual * np.log(clip))\n",
        "    return -1.0 / rows * vsota"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HykjZHTdMqca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lbl_enc = preprocessing.LabelEncoder()\n",
        "y = lbl_enc.fit_transform(train.author.values)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nXqf-D7Msoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, y, \n",
        "                                                  stratify=y, \n",
        "                                                  random_state=42, \n",
        "                                                  test_size=0.1, shuffle=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x7cvPTTMvMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7966009d-8200-48de-9315-5594a1d30a22"
      },
      "source": [
        "print (xtrain.shape)\n",
        "print (xvalid.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17621,)\n",
            "(1958,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9zfN-4PMxYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = 'english')\n",
        "\n",
        "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
        "tfv.fit(list(xtrain) + list(xvalid))\n",
        "xtrain_tfv =  tfv.transform(xtrain) \n",
        "xvalid_tfv = tfv.transform(xvalid)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ74g7ORMy4c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "e7d7fc40-9d02-49f7-ceea-e06eb4550bf2"
      },
      "source": [
        "# Fitting a simple Logistic Regression on TFIDF\n",
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.572 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzeIwJPcM09s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), stop_words = 'english')\n",
        "\n",
        "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
        "ctv.fit(list(xtrain) + list(xvalid))\n",
        "xtrain_ctv =  ctv.transform(xtrain) \n",
        "xvalid_ctv = ctv.transform(xvalid)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goWvyhIFM2Xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "537797ea-c456-462e-8601-7765683c3ab8"
      },
      "source": [
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(xtrain_ctv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_ctv)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.527 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI8Bs8MxM6KL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f3bf450-4f2b-4a4c-cc91-b5bb66234c4c"
      },
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.578 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V__ghYVnM8hO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0b33de7-3781-4c07-acb6-8e8b7462aed4"
      },
      "source": [
        "# Fitting a simple Naive Bayes on Counts\n",
        "clf = MultinomialNB()\n",
        "clf.fit(xtrain_ctv, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_ctv)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.485 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O38jc4-M-t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svd = decomposition.TruncatedSVD(n_components=120)\n",
        "svd.fit(xtrain_tfv)\n",
        "xtrain_svd = svd.transform(xtrain_tfv)\n",
        "xvalid_svd = svd.transform(xvalid_tfv)\n",
        "\n",
        "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
        "scl = preprocessing.StandardScaler()\n",
        "scl.fit(xtrain_svd)\n",
        "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
        "xvalid_svd_scl = scl.transform(xvalid_svd)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HDKktlgM_Ot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ef0e162-754a-4703-f028-4af11f7508f7"
      },
      "source": [
        "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
        "clf.fit(xtrain_svd_scl, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_svd_scl)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.729 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlgEUXKBNClW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64b9f486-c06f-406b-a7bd-9310b3c276e2"
      },
      "source": [
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
        "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.782 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_arMlLUNENe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34869005-e21a-4fd2-9eb7-83dd63463c5f"
      },
      "source": [
        "# Fitting a simple xgboost on tf-idf\n",
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_ctv.tocsc(), ytrain)\n",
        "predictions = clf.predict_proba(xvalid_ctv.tocsc())\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.773 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMpBHUgmNGP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fda9df8-f021-457a-8e27-c7302975eefb"
      },
      "source": [
        "# Fitting a simple xgboost on tf-idf svd features\n",
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_svd, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_svd)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "logloss: 0.766 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ffTQlz6NIec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS1n1sqENNVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize SVD\n",
        "svd = TruncatedSVD()\n",
        "    \n",
        "# Initialize the standard scaler \n",
        "scl = preprocessing.StandardScaler()\n",
        "\n",
        "# We will use logistic regression here..\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "# Create the pipeline \n",
        "clf = pipeline.Pipeline([('svd', svd),\n",
        "                         ('scl', scl),\n",
        "                         ('lr', lr_model)])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_qc7dcpNN0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {'svd__n_components' : [120, 180],\n",
        "              'lr__C': [0.1, 1.0, 10], \n",
        "              'lr__penalty': ['l1', 'l2']}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bsGfEDiNQAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e3a9f9fb-3b7b-47db-b020-55117e2909de"
      },
      "source": [
        "# Initialize Grid Search Model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
        "\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain\n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.2s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   13.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   19.4s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   30.2s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   34.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   34.0s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: -0.739\n",
            "Best parameters set:\n",
            "\tlr__C: 1.0\n",
            "\tlr__penalty: 'l2'\n",
            "\tsvd__n_components: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jZhvVGZNSNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "43e44f80-01e7-4751-f6be-45291952c6fa"
      },
      "source": [
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Create the pipeline \n",
        "clf = pipeline.Pipeline([('nb', nb_model)])\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Initialize Grid Search Model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
        "\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain. \n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0561s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0926s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score: -0.492\n",
            "Best parameters set:\n",
            "\tnb__alpha: 0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.2s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pwUBz7lbRs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "46bb6dbd-9421-4076-ac98-53620dec5ae5"
      },
      "source": [
        "\n",
        "embeddings_index = {}\n",
        "f = open('glove.840B.300d.txt')\n",
        "for line in tqdm(f):\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-ad19050fe8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove.840B.300d.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.840B.300d.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWHxbgNzNam5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent2vec(s):\n",
        "    words = str(s).lower().decode('utf-8')\n",
        "    words = word_tokenize(words)\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    words = [w for w in words if w.isalpha()]\n",
        "    M = []\n",
        "    for w in words:\n",
        "        try:\n",
        "            M.append(embeddings_index[w])\n",
        "        except:\n",
        "            continue\n",
        "    M = np.array(M)\n",
        "    v = M.sum(axis=0)\n",
        "    if type(v) != np.ndarray:\n",
        "        return np.zeros(300)\n",
        "    return v / np.sqrt((v ** 2).sum())"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URpV88ETNcdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "52ec4e69-692b-41de-a640-e113fd3c8eed"
      },
      "source": [
        "# create sentence vectors using the above function for training and validation set\n",
        "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
        "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/17621 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d7255ae69e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create sentence vectors using the above function for training and validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxtrain_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxvalid_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-d7255ae69e29>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create sentence vectors using the above function for training and validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxtrain_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxvalid_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-88340a73b13f>\u001b[0m in \u001b[0;36msent2vec\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msent2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKYRLhT1bf9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "0d85138f-2689-4b8c-afab-cfe6c5a19730"
      },
      "source": [
        "xtrain_glove = np.array(xtrain_glove)\n",
        "xvalid_glove = np.array(xvalid_glove)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-6da67e992d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxtrain_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxvalid_glove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xtrain_glove' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS1gtqh-bjmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "fb523b21-7fc9-40bf-f7dc-772f7594aa2c"
      },
      "source": [
        "# Fitting a simple xgboost on glove features\n",
        "clf = xgb.XGBClassifier(nthread=10, silent=False)\n",
        "clf.fit(xtrain_glove, ytrain)\n",
        "predictions = clf.predict_proba(xvalid_glove)\n",
        "\n",
        "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-bb1bdc46f32d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fitting a simple xgboost on glove features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_glove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xtrain_glove' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTMCAkuZbnip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c1d2cce9-2017-4657-f6c7-61ebdf7c5606"
      },
      "source": [
        "scl = preprocessing.StandardScaler()\n",
        "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
        "xvalid_glove_scl = scl.transform(xvalid_glove)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-4dda162ca77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxtrain_glove_scl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mxvalid_glove_scl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxvalid_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xtrain_glove' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMeCb4P6brCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ytrain_enc = np_utils.to_categorical(ytrain)\n",
        "yvalid_enc = np_utils.to_categorical(yvalid)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsKqzyWwbtSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a simple 3 layer sequential neural net\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(300, input_dim=300, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB5_0SeibvPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "6409a437-6cc3-41f4-df6e-ec00a437c6bf"
      },
      "source": [
        "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n",
        "          epochs=5, verbose=1, \n",
        "          validation_data=(xvalid_glove_scl, yvalid_enc))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-801b2988c443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           validation_data=(xvalid_glove_scl, yvalid_enc))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xtrain_glove_scl' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWcVUtwENp41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 70\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "\n",
        "# zero pad the sequences\n",
        "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "\n",
        "word_index = token.word_index"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-SrgBZsNqdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "9ad25667-3504-4912-f086-b52412731efc"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "100%|| 25943/25943 [00:00<00:00, 1242368.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyWy7yDcNslS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A simple LSTM with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQp5x_Q-cAFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccb1549a-cc9b-4206-e4df-419b53b7e012"
      },
      "source": [
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, verbose=1, validation_data=(xvalid_pad, yvalid_enc))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17621 samples, validate on 1958 samples\n",
            "Epoch 1/100\n",
            "17621/17621 [==============================] - 9s 538us/step - loss: 1.0968 - val_loss: 1.0949\n",
            "Epoch 2/100\n",
            "17621/17621 [==============================] - 7s 419us/step - loss: 1.0935 - val_loss: 1.0921\n",
            "Epoch 3/100\n",
            "17621/17621 [==============================] - 7s 408us/step - loss: 1.0912 - val_loss: 1.0903\n",
            "Epoch 4/100\n",
            "17621/17621 [==============================] - 7s 408us/step - loss: 1.0897 - val_loss: 1.0891\n",
            "Epoch 5/100\n",
            "17621/17621 [==============================] - 7s 424us/step - loss: 1.0887 - val_loss: 1.0884\n",
            "Epoch 6/100\n",
            "17621/17621 [==============================] - 7s 418us/step - loss: 1.0882 - val_loss: 1.0880\n",
            "Epoch 7/100\n",
            "17621/17621 [==============================] - 7s 414us/step - loss: 1.0879 - val_loss: 1.0878\n",
            "Epoch 8/100\n",
            "17621/17621 [==============================] - 7s 422us/step - loss: 1.0877 - val_loss: 1.0876\n",
            "Epoch 9/100\n",
            "17621/17621 [==============================] - 7s 420us/step - loss: 1.0876 - val_loss: 1.0876\n",
            "Epoch 10/100\n",
            "17621/17621 [==============================] - 7s 410us/step - loss: 1.0876 - val_loss: 1.0875\n",
            "Epoch 11/100\n",
            "17621/17621 [==============================] - 7s 410us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 12/100\n",
            "17621/17621 [==============================] - 7s 410us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 13/100\n",
            "17621/17621 [==============================] - 7s 408us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 14/100\n",
            "17621/17621 [==============================] - 7s 414us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 15/100\n",
            "17621/17621 [==============================] - 7s 406us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 16/100\n",
            "17621/17621 [==============================] - 7s 416us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 17/100\n",
            "17621/17621 [==============================] - 7s 415us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 18/100\n",
            "17621/17621 [==============================] - 7s 408us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 19/100\n",
            "17621/17621 [==============================] - 7s 409us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 20/100\n",
            "17621/17621 [==============================] - 7s 407us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 21/100\n",
            "17621/17621 [==============================] - 7s 405us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 22/100\n",
            "17621/17621 [==============================] - 7s 409us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 23/100\n",
            "17621/17621 [==============================] - 7s 406us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 24/100\n",
            "17621/17621 [==============================] - 7s 414us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 25/100\n",
            "17621/17621 [==============================] - 7s 413us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 26/100\n",
            "17621/17621 [==============================] - 7s 400us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 27/100\n",
            "17621/17621 [==============================] - 7s 413us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 28/100\n",
            "17621/17621 [==============================] - 7s 411us/step - loss: 1.0876 - val_loss: 1.0875\n",
            "Epoch 29/100\n",
            "17621/17621 [==============================] - 7s 417us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 30/100\n",
            "17621/17621 [==============================] - 7s 417us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 31/100\n",
            "17621/17621 [==============================] - 7s 421us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 32/100\n",
            "17621/17621 [==============================] - 7s 395us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 33/100\n",
            "17621/17621 [==============================] - 7s 399us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 34/100\n",
            "17621/17621 [==============================] - 7s 406us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 35/100\n",
            "17621/17621 [==============================] - 7s 400us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 36/100\n",
            "17621/17621 [==============================] - 7s 401us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 37/100\n",
            "17621/17621 [==============================] - 7s 401us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 38/100\n",
            "17621/17621 [==============================] - 7s 412us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 39/100\n",
            "17621/17621 [==============================] - 7s 406us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 40/100\n",
            "17621/17621 [==============================] - 7s 407us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 41/100\n",
            "17621/17621 [==============================] - 7s 410us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 42/100\n",
            "17621/17621 [==============================] - 7s 408us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 43/100\n",
            "17621/17621 [==============================] - 7s 409us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 44/100\n",
            "17621/17621 [==============================] - 7s 399us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 45/100\n",
            "17621/17621 [==============================] - 7s 404us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 46/100\n",
            "17621/17621 [==============================] - 7s 402us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 47/100\n",
            "17621/17621 [==============================] - 7s 411us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 48/100\n",
            "17621/17621 [==============================] - 7s 417us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 49/100\n",
            "17621/17621 [==============================] - 7s 411us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 50/100\n",
            "17621/17621 [==============================] - 7s 405us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 51/100\n",
            "17621/17621 [==============================] - 7s 409us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 52/100\n",
            "17621/17621 [==============================] - 7s 404us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 53/100\n",
            "17621/17621 [==============================] - 7s 407us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 54/100\n",
            "17621/17621 [==============================] - 7s 406us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 55/100\n",
            "17621/17621 [==============================] - 7s 416us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 56/100\n",
            "17621/17621 [==============================] - 7s 390us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 57/100\n",
            "17621/17621 [==============================] - 7s 404us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 58/100\n",
            "17621/17621 [==============================] - 7s 413us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 59/100\n",
            "17621/17621 [==============================] - 7s 402us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 60/100\n",
            "17621/17621 [==============================] - 7s 417us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 61/100\n",
            "17621/17621 [==============================] - 7s 416us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 62/100\n",
            "17621/17621 [==============================] - 7s 409us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 63/100\n",
            "17621/17621 [==============================] - 7s 409us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 64/100\n",
            "17621/17621 [==============================] - 7s 414us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 65/100\n",
            "17621/17621 [==============================] - 7s 410us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 66/100\n",
            "17621/17621 [==============================] - 7s 396us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 67/100\n",
            "17621/17621 [==============================] - 7s 403us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 68/100\n",
            "17621/17621 [==============================] - 7s 400us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 69/100\n",
            "17621/17621 [==============================] - 7s 405us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 70/100\n",
            "17621/17621 [==============================] - 7s 405us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 71/100\n",
            "17621/17621 [==============================] - 7s 402us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 72/100\n",
            "17621/17621 [==============================] - 7s 422us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 73/100\n",
            "17621/17621 [==============================] - 7s 419us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 74/100\n",
            "17621/17621 [==============================] - 7s 415us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 75/100\n",
            "17621/17621 [==============================] - 7s 406us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 76/100\n",
            "17621/17621 [==============================] - 7s 407us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 77/100\n",
            "17621/17621 [==============================] - 7s 413us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 78/100\n",
            "17621/17621 [==============================] - 7s 398us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 79/100\n",
            "17621/17621 [==============================] - 7s 408us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 80/100\n",
            "17621/17621 [==============================] - 7s 399us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 81/100\n",
            "17621/17621 [==============================] - 7s 399us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 82/100\n",
            "17621/17621 [==============================] - 7s 404us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 83/100\n",
            "17621/17621 [==============================] - 7s 401us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 84/100\n",
            "17621/17621 [==============================] - 7s 411us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 85/100\n",
            "17621/17621 [==============================] - 7s 405us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 86/100\n",
            "17621/17621 [==============================] - 7s 404us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 87/100\n",
            "17621/17621 [==============================] - 7s 413us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 88/100\n",
            "17621/17621 [==============================] - 7s 417us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 89/100\n",
            "17621/17621 [==============================] - 7s 401us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 90/100\n",
            "17621/17621 [==============================] - 7s 408us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 91/100\n",
            "17621/17621 [==============================] - 7s 408us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 92/100\n",
            "17621/17621 [==============================] - 7s 412us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 93/100\n",
            "17621/17621 [==============================] - 7s 399us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 94/100\n",
            "17621/17621 [==============================] - 7s 409us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 95/100\n",
            "17621/17621 [==============================] - 7s 415us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 96/100\n",
            "17621/17621 [==============================] - 7s 409us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 97/100\n",
            "17621/17621 [==============================] - 7s 405us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 98/100\n",
            "17621/17621 [==============================] - 7s 410us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 99/100\n",
            "17621/17621 [==============================] - 7s 401us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 100/100\n",
            "17621/17621 [==============================] - 7s 404us/step - loss: 1.0875 - val_loss: 1.0875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7faf539349b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGHy0QjdfAEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "a642d8a1-c9df-41cb-f782-30d662679633"
      },
      "source": [
        "# A simple LSTM with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(LSTM(300, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Fit the model with early stopping callback\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
        "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17621 samples, validate on 1958 samples\n",
            "Epoch 1/100\n",
            "17621/17621 [==============================] - 9s 535us/step - loss: 1.0966 - val_loss: 1.0947\n",
            "Epoch 2/100\n",
            "17621/17621 [==============================] - 9s 499us/step - loss: 1.0932 - val_loss: 1.0919\n",
            "Epoch 3/100\n",
            "17621/17621 [==============================] - 9s 511us/step - loss: 1.0910 - val_loss: 1.0900\n",
            "Epoch 4/100\n",
            "17621/17621 [==============================] - 9s 500us/step - loss: 1.0894 - val_loss: 1.0889\n",
            "Epoch 5/100\n",
            "17621/17621 [==============================] - 9s 513us/step - loss: 1.0886 - val_loss: 1.0883\n",
            "Epoch 6/100\n",
            "17621/17621 [==============================] - 9s 510us/step - loss: 1.0881 - val_loss: 1.0879\n",
            "Epoch 7/100\n",
            "17621/17621 [==============================] - 9s 494us/step - loss: 1.0878 - val_loss: 1.0877\n",
            "Epoch 8/100\n",
            "17621/17621 [==============================] - 9s 499us/step - loss: 1.0877 - val_loss: 1.0876\n",
            "Epoch 9/100\n",
            "17621/17621 [==============================] - 9s 493us/step - loss: 1.0876 - val_loss: 1.0876\n",
            "Epoch 10/100\n",
            "17621/17621 [==============================] - 9s 504us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 11/100\n",
            "17621/17621 [==============================] - 9s 497us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 12/100\n",
            "17621/17621 [==============================] - 9s 503us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 13/100\n",
            "17621/17621 [==============================] - 9s 507us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 14/100\n",
            "17621/17621 [==============================] - 9s 499us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 15/100\n",
            "17621/17621 [==============================] - 9s 504us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 16/100\n",
            "17621/17621 [==============================] - 9s 504us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 17/100\n",
            "17621/17621 [==============================] - 9s 502us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 18/100\n",
            "17621/17621 [==============================] - 9s 502us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 19/100\n",
            "17621/17621 [==============================] - 9s 492us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 20/100\n",
            "17621/17621 [==============================] - 9s 508us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 21/100\n",
            "17621/17621 [==============================] - 9s 496us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 22/100\n",
            "17621/17621 [==============================] - 9s 492us/step - loss: 1.0875 - val_loss: 1.0875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7faf52d07518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlO1vp9wf96T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "fda1973f-366d-443d-ba14-eba5fc68e1f9"
      },
      "source": [
        "# A simple bidirectional LSTM with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Fit the model with early stopping callback\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
        "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17621 samples, validate on 1958 samples\n",
            "Epoch 1/100\n",
            "17621/17621 [==============================] - 18s 1ms/step - loss: 1.0967 - val_loss: 1.0947\n",
            "Epoch 2/100\n",
            "17621/17621 [==============================] - 17s 959us/step - loss: 1.0932 - val_loss: 1.0919\n",
            "Epoch 3/100\n",
            "17621/17621 [==============================] - 17s 960us/step - loss: 1.0909 - val_loss: 1.0900\n",
            "Epoch 4/100\n",
            "17621/17621 [==============================] - 17s 951us/step - loss: 1.0894 - val_loss: 1.0889\n",
            "Epoch 5/100\n",
            "17621/17621 [==============================] - 17s 952us/step - loss: 1.0886 - val_loss: 1.0883\n",
            "Epoch 6/100\n",
            "17621/17621 [==============================] - 17s 973us/step - loss: 1.0881 - val_loss: 1.0879\n",
            "Epoch 7/100\n",
            "17621/17621 [==============================] - 16s 932us/step - loss: 1.0878 - val_loss: 1.0877\n",
            "Epoch 8/100\n",
            "17621/17621 [==============================] - 17s 963us/step - loss: 1.0877 - val_loss: 1.0876\n",
            "Epoch 9/100\n",
            "17621/17621 [==============================] - 17s 951us/step - loss: 1.0876 - val_loss: 1.0876\n",
            "Epoch 10/100\n",
            "17621/17621 [==============================] - 17s 955us/step - loss: 1.0876 - val_loss: 1.0876\n",
            "Epoch 11/100\n",
            "17621/17621 [==============================] - 17s 964us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 12/100\n",
            "17621/17621 [==============================] - 17s 966us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 13/100\n",
            "17621/17621 [==============================] - 17s 971us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 14/100\n",
            "17621/17621 [==============================] - 17s 953us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 15/100\n",
            "17621/17621 [==============================] - 17s 972us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 16/100\n",
            "17621/17621 [==============================] - 17s 951us/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 17/100\n",
            "17621/17621 [==============================] - 17s 954us/step - loss: 1.0875 - val_loss: 1.0875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7faf4e3c7780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9jHCOHvgiJj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "cbf549af-ff2c-4605-fec5-9934c043f713"
      },
      "source": [
        "# GRU with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     weights=[embedding_matrix],\n",
        "                     input_length=max_len,\n",
        "                     trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
        "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(3))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Fit the model with early stopping callback\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
        "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
        "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17621 samples, validate on 1958 samples\n",
            "Epoch 1/100\n",
            "17621/17621 [==============================] - 22s 1ms/step - loss: 1.0966 - val_loss: 1.0947\n",
            "Epoch 2/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0933 - val_loss: 1.0919\n",
            "Epoch 3/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0910 - val_loss: 1.0901\n",
            "Epoch 4/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0895 - val_loss: 1.0890\n",
            "Epoch 5/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0886 - val_loss: 1.0884\n",
            "Epoch 6/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0881 - val_loss: 1.0879\n",
            "Epoch 7/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0878 - val_loss: 1.0877\n",
            "Epoch 8/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0877 - val_loss: 1.0876\n",
            "Epoch 9/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0876 - val_loss: 1.0876\n",
            "Epoch 10/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 11/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 12/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 13/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 14/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 15/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 16/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 17/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 18/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n",
            "Epoch 19/100\n",
            "17621/17621 [==============================] - 21s 1ms/step - loss: 1.0875 - val_loss: 1.0875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7faf4002e5c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}